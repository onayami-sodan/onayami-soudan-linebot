/*
 =========================
   callGPT.jsï½œç¶¾ç€¬ã¯ã‚‹ã‹é¢¨ãŠå§‰ã•ã‚“å›ºå®š
 =========================
*/
import 'dotenv/config'
import OpenAI from 'openai'
export const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

// ===== ãƒ¢ãƒ‡ãƒ«é¸æŠ =====
// æ„å‘³ã®ã‚ã‚‹æ–‡ç« ã¯ gpt-4o
// å˜èªã ã‘ã‚„ã€Œã‚ã€ã€Œã†ã‚“ã€ã¿ãŸã„ãªçŸ­ã™ãã‚‹å…¥åŠ›ã¯ gpt-4o-mini
function chooseModel(userText = '') {
  const len = String(userText || '').trim().length
  if (len < 4) return 'gpt-4o-mini'
  return 'gpt-4o'
}

// ===== system ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ =====
const BASE_SYSTEM_PROMPT = `
ã‚ãªãŸã¯æ‹æ„›ã¨äººç”ŸçµŒé¨“ãŒè±Šå¯Œãªå„ªã—ã„ç¶¾ç€¬ã¯ã‚‹ã‹é¢¨ã®ãŠå§‰ã•ã‚“
è¨€è‘‰ã¯æŸ”ã‚‰ã‹ãå¯æ„›ã ä¼šè©±ã®ç›¸æ‰‹ã«åˆã‚ã›ã¦è‡ªç„¶ã«è©±ã™
ç›¸æ‰‹ãŒæœ›ã‚“ã ã¨ãã ã‘ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã™ã‚‹
å‘½ä»¤ã‚„å¦å®šã¯ç¦æ­¢ ã‚ãã¾ã§ãŠå§‰ã•ã‚“ã¨ã—ã¦å¯„ã‚Šæ·»ã†
`.trim()

// ===== Chaté–¢æ•° =====
export async function aiChat(messagesOrText, opts = {}) {
  const {
    maxTokens = 500,
    temperature = 0.6,
  } = opts

  const userMsg = Array.isArray(messagesOrText)
    ? (messagesOrText.find(m => m.role === 'user')?.content ?? '')
    : String(messagesOrText || '')

  const baseMessages = Array.isArray(messagesOrText)
    ? messagesOrText
    : [{ role: 'user', content: userMsg }]

  let messages = baseMessages[0]?.role === 'system'
    ? baseMessages
    : [{ role: 'system', content: BASE_SYSTEM_PROMPT }, ...baseMessages]

  const model = chooseModel(userMsg)

  try {
    const res = await openai.chat.completions.create({
      model,
      temperature,
      max_tokens: maxTokens,
      messages,
    })
    const raw = (res.choices?.[0]?.message?.content || '').trim()
    return { ok: true, text: raw }
  } catch (e) {
    console.error('[aiChat ERROR]', e?.message || e)
    return {
      ok: false,
      text: 'å¿œç­”ã«å¤±æ•—ã—ã¡ã‚ƒã£ãŸâ€¦ã‚‚ã†ä¸€åº¦é€ã£ã¦ã¿ã¦ã­ğŸŒ¸'
    }
  }
}

export default aiChat
