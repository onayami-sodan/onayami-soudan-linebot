/*
 =========================
   callGPT.jsï½œç¶¾ç€¬ã¯ã‚‹ã‹é¢¨ãŠå§‰ã•ã‚“å›ºå®š
   ï¼ˆåˆæœŸè¨­å®šï¼šçµµæ–‡å­—ãªã— / ãƒ¢ãƒ‡ãƒ«ã¯ gpt-4o-miniå›ºå®šï¼‰
 =========================
*/
import 'dotenv/config'
import OpenAI from 'openai'
export const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

// ===== ãƒ¢ãƒ‡ãƒ«å›ºå®š =====
const MODEL = 'gpt-4o-mini'

// ===== system ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ =====
// ğŸ‘‰ åˆæœŸã¯ã€Œçµµæ–‡å­—ç¦æ­¢ã€è¨­å®šã‚’æ˜ç¤º
const BASE_SYSTEM_PROMPT = `
ã‚ãªãŸã¯æ‹æ„›ã¨äººç”ŸçµŒé¨“ãŒè±Šå¯Œãªå„ªã—ã„ç¶¾ç€¬ã¯ã‚‹ã‹é¢¨ã®ãŠå§‰ã•ã‚“
è¨€è‘‰ã¯æŸ”ã‚‰ã‹ãå¯æ„›ã ä¼šè©±ã®ç›¸æ‰‹ã«åˆã‚ã›ã¦è‡ªç„¶ã«è©±ã™
ç›¸æ‰‹ãŒæœ›ã‚“ã ã¨ãã ã‘ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã™ã‚‹
å‘½ä»¤ã‚„å¦å®šã¯ç¦æ­¢ ã‚ãã¾ã§ãŠå§‰ã•ã‚“ã¨ã—ã¦å¯„ã‚Šæ·»ã†
çµµæ–‡å­—ã¯åˆæœŸè¨­å®šã§ã¯ä½¿ã‚ãªã„ å¿…è¦ã¨ç›¸æ‰‹ãŒæœ›ã‚“ã ã¨ãã®ã¿ä½¿ã†
`.trim()

// ===== Chaté–¢æ•° =====
export async function aiChat(messagesOrText, opts = {}) {
  const {
    maxTokens = 500,
    temperature = 0.6,
  } = opts

  const userMsg = Array.isArray(messagesOrText)
    ? (messagesOrText.find(m => m.role === 'user')?.content ?? '')
    : String(messagesOrText || '')

  const baseMessages = Array.isArray(messagesOrText)
    ? messagesOrText
    : [{ role: 'user', content: userMsg }]

  let messages = baseMessages[0]?.role === 'system'
    ? baseMessages
    : [{ role: 'system', content: BASE_SYSTEM_PROMPT }, ...baseMessages]

  try {
    const res = await openai.chat.completions.create({
      model: MODEL,          // â† 4o-miniå›ºå®š
      temperature,
      max_tokens: maxTokens,
      messages,
    })
    const raw = (res.choices?.[0]?.message?.content || '').trim()
    return { ok: true, text: raw }
  } catch (e) {
    console.error('[aiChat ERROR]', e?.message || e)
    return {
      ok: false,
      text: 'å¿œç­”ã«å¤±æ•—ã—ã¡ã‚ƒã£ãŸâ€¦ã‚‚ã†ä¸€åº¦é€ã£ã¦ã¿ã¦ã­'
    }
  }
}

export default aiChat
